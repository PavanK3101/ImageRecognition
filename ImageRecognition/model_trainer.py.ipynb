{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8720f14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.applications import MobileNetV2, ResNet50, VGG16\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "class ModelTrainer:\n",
    "    \"\"\"Handles model creation, training, and management\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "        self.class_names = []\n",
    "        self.training_history = {}\n",
    "        \n",
    "    def create_model(self, num_classes: int, model_type: str = 'mobilenet') -> tf.keras.Model:\n",
    "        \"\"\"\n",
    "        Create a CNN model for image classification\n",
    "        \n",
    "        Args:\n",
    "            num_classes: Number of classes to classify\n",
    "            model_type: Type of model ('mobilenet', 'resnet', 'vgg', 'custom')\n",
    "            \n",
    "        Returns:\n",
    "            Compiled Keras model\n",
    "        \"\"\"\n",
    "        input_shape = (*self.config.IMAGE_SIZE, 3)\n",
    "        \n",
    "        if model_type == 'mobilenet':\n",
    "            base_model = MobileNetV2(\n",
    "                weights='imagenet',\n",
    "                include_top=False,\n",
    "                input_shape=input_shape\n",
    "            )\n",
    "        elif model_type == 'resnet':\n",
    "            base_model = ResNet50(\n",
    "                weights='imagenet',\n",
    "                include_top=False,\n",
    "                input_shape=input_shape\n",
    "            )\n",
    "        elif model_type == 'vgg':\n",
    "            base_model = VGG16(\n",
    "                weights='imagenet',\n",
    "                include_top=False,\n",
    "                input_shape=input_shape\n",
    "            )\n",
    "        else:  # custom model\n",
    "            return self._create_custom_model(input_shape, num_classes)\n",
    "        \n",
    "        # Freeze base model initially\n",
    "        base_model.trainable = False\n",
    "        \n",
    "        # Add custom top layers\n",
    "        model = models.Sequential([\n",
    "            base_model,\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            layers.Dropout(0.2),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dropout(0.2),\n",
    "            layers.Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        # Compile model\n",
    "        model.compile(\n",
    "            optimizer=optimizers.Adam(learning_rate=self.config.LEARNING_RATE),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy', 'top_k_categorical_accuracy']\n",
    "        )\n",
    "        \n",
    "        self.model = model\n",
    "        return model\n",
    "    \n",
    "    def _create_custom_model(self, input_shape: Tuple, num_classes: int) -> tf.keras.Model:\n",
    "        \"\"\"Create a custom CNN model from scratch\"\"\"\n",
    "        model = models.Sequential([\n",
    "            layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(512, activation='relu'),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=optimizers.Adam(learning_rate=self.config.LEARNING_RATE),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train_model(self, train_data, validation_data, class_names: List[str]) -> dict:\n",
    "        \"\"\"\n",
    "        Train the model with given data\n",
    "        \n",
    "        Args:\n",
    "            train_data: Training data generator\n",
    "            validation_data: Validation data generator\n",
    "            class_names: List of class names\n",
    "            \n",
    "        Returns:\n",
    "            Training history\n",
    "        \"\"\"\n",
    "        self.class_names = class_names\n",
    "        \n",
    "        # Callbacks\n",
    "        callbacks = [\n",
    "            EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=5,\n",
    "                restore_best_weights=True\n",
    "            ),\n",
    "            ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.2,\n",
    "                patience=3,\n",
    "                min_lr=0.001\n",
    "            ),\n",
    "            ModelCheckpoint(\n",
    "                filepath=str(self.config.MODEL_FOLDER / f'{self.config.MODEL_NAME}_best.h5'),\n",
    "                monitor='val_accuracy',\n",
    "                save_best_only=True\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # Train model\n",
    "        history = self.model.fit(\n",
    "            train_data,\n",
    "            epochs=self.config.EPOCHS,\n",
    "            validation_data=validation_data,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        self.training_history = history.history\n",
    "        return history.history\n",
    "    \n",
    "    def save_model(self, model_path: Optional[str] = None):\n",
    "        \"\"\"Save the trained model and metadata\"\"\"\n",
    "        if model_path is None:\n",
    "            model_path = self.config.MODEL_FOLDER / f'{self.config.MODEL_NAME}.h5'\n",
    "        \n",
    "        # Save model\n",
    "        self.model.save(model_path)\n",
    "        \n",
    "        # Save metadata\n",
    "        metadata = {\n",
    "            'class_names': self.class_names,\n",
    "            'image_size': self.config.IMAGE_SIZE,\n",
    "            'model_name': self.config.MODEL_NAME,\n",
    "            'training_date': datetime.now().isoformat(),\n",
    "            'training_history': self.training_history\n",
    "        }\n",
    "        \n",
    "        metadata_path = str(model_path).replace('.h5', '_metadata.json')\n",
    "        with open(metadata_path, 'w') as f:\n",
    "            json.dump(metadata, f, indent=2)\n",
    "        \n",
    "        logger.info(f\"Model saved to {model_path}\")\n",
    "    \n",
    "    def load_model(self, model_path: str):\n",
    "        \"\"\"Load a trained model and its metadata\"\"\"\n",
    "        self.model = tf.keras.models.load_model(model_path)\n",
    "        \n",
    "        # Load metadata\n",
    "        metadata_path = model_path.replace('.h5', '_metadata.json')\n",
    "        try:\n",
    "            with open(metadata_path, 'r') as f:\n",
    "                metadata = json.load(f)\n",
    "            self.class_names = metadata.get('class_names', [])\n",
    "            self.training_history = metadata.get('training_history', {})\n",
    "        except FileNotFoundError:\n",
    "            logger.warning(f\"Metadata file not found: {metadata_path}\")\n",
    "    \n",
    "    def predict(self, image_array: np.ndarray) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Make predictions on preprocessed image\n",
    "        \n",
    "        Args:\n",
    "            image_array: Preprocessed image array\n",
    "            \n",
    "        Returns:\n",
    "            List of predictions with confidence scores\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "        \n",
    "        # Make prediction\n",
    "        predictions = self.model.predict(image_array, verbose=0)\n",
    "        \n",
    "        # Get top predictions\n",
    "        top_indices = np.argsort(predictions[0])[::-1][:self.config.TOP_K_PREDICTIONS]\n",
    "        \n",
    "        results = []\n",
    "        for idx in top_indices:\n",
    "            confidence = float(predictions[0][idx])\n",
    "            if confidence >= self.config.CONFIDENCE_THRESHOLD:\n",
    "                class_name = self.class_names[idx] if idx < len(self.class_names) else f\"Class_{idx}\"\n",
    "                results.append({\n",
    "                    'class': class_name,\n",
    "                    'confidence': confidence,\n",
    "                    'percentage': confidence * 100\n",
    "                })\n",
    "        \n",
    "        return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
